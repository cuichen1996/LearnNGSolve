{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60481bb3-8a35-46a6-b015-fccdcfde64cd",
   "metadata": {},
   "source": [
    "# A posteriori error estimates\n",
    "\n",
    "We will derive methods to estimate the error of the computed finite\n",
    "element approximation. Such **a posteriori** error estimates may use the finite element solution $u_h$, and input data such as the source term $f$. \n",
    "\n",
    "$$\n",
    "\\eta(u_h, f)\n",
    "$$\n",
    "\n",
    "An error estimator is called **reliable**, if it is an upper bound for the error,\n",
    "i.e., there exists a constant $C_1$ such that\n",
    "\n",
    "$$\n",
    "\\| u - u_h \\|_V \\leq C_1 \\, \\eta(u_h, f)\n",
    "$$\n",
    "\n",
    "An error estimator is **efficient**, if it is a lower bound for the error,\n",
    "i.e., there exists a constant $C_2$ such that\n",
    "\n",
    "$$\n",
    "\\| u - u_h \\|_V \\geq C_2 \\, \\eta(u_h, f).\n",
    "$$\n",
    "\n",
    "The constants may depend on the domain, and the shape of the triangles,\n",
    "but may not depend on the source term $f$, or the (unknown)\n",
    "solution $u$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625df5f5-b6ae-4705-92aa-74f881f45d6c",
   "metadata": {},
   "source": [
    "One use of the a posteriori error estimator is to know the accuracy of\n",
    "the finite element approximation. A second one is to guide the\n",
    "construction of a new mesh to improve the accuracy of a new finite\n",
    "element approximation.\n",
    " \n",
    "The usual error estimators are defined as sum over element contributions:\n",
    "\n",
    "$$\n",
    "\\eta^2 (u_h, f) = \\sum_{T \\in {\\cal T}} \\eta_T^2 (u_h, f)\n",
    "$$\n",
    "\n",
    "The local contributions should correspond to the local error. For\n",
    "the common error estimators there hold the local efficiency estimates\n",
    "\n",
    "$$\n",
    "\\| u - u_h \\|_{H^1(\\omega_T)} \\geq C_2 \\, \\eta_T(u_h, f).\n",
    "$$\n",
    "The patch $\\omega_T$ contains $T$ and all its neighbor elements.\n",
    "\n",
    "\n",
    "In the following, we consider the Poisson equation $-\\Delta u = f$ with\n",
    "homogeneous Dirichlet boundary conditions $u = 0$ on $\\partial \\Omega$. We choose piecewise linear finite elements on triangles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9f2908-815a-4380-b3f2-95ce6fe27ff7",
   "metadata": {},
   "source": [
    "## The Zienkiewicz Zhu error estimator\n",
    "The simplest a posteriori error estimator is the one by\n",
    "Zienkiewicz and Zhu, the so called ZZ error estimator.\n",
    "\n",
    "The error is measured in the $H^1$-semi norm:\n",
    "\n",
    "$$\n",
    "\\| \\nabla u - \\nabla u_h \\|_{L_2}\n",
    "$$\n",
    "\n",
    "Define the gradient $p = \\nabla u$ and the discrete gradient $p_h = \\nabla u_h$. \n",
    "The discrete gradient $p_h$ is a constant on each element. \n",
    "Let $\\tilde p_h$ be the p.w. linear and continuous\n",
    "finite element function obtained by averaging the element values of $p_h$ in the vertices:\n",
    "\n",
    "$$\n",
    "\\tilde p_h(x_i) = \\frac{1}{ | \\{ T : x_i \\in T \\} |} \\sum_{T : x_i \\in T} \n",
    "        p_{h|T}\n",
    "\\qquad \\mbox{for all vertices } x_i\n",
    "$$\n",
    "The hope is that the averaged gradient is a much better approximation to the true gradient,\n",
    "i.e.,\n",
    "\n",
    "$$\n",
    "\\| p - \\tilde p_h \\|_{L_2} \\leq \\alpha \\, \\| p - p_h \\|_{L_2}\n",
    "$$\n",
    "holds with a small constant $\\alpha \\ll 1$. This property is known as *super-convergence*.It is indeed true on (locally) uniform meshes, and smoothness assumptions onto the source term $f$. \n",
    "\n",
    "The ZZ error estimator replaces the true gradient in the error $p-p_h$ by the good approximation $\\tilde p_h$:\n",
    "\n",
    "$$\n",
    "\\eta (u_h) = \\| \\tilde p_h - p_h \\|_{L_2(\\Omega)}\n",
    "$$\n",
    "\n",
    "If the super-convergence property is fulfilled, \n",
    "than the ZZ error estimator is reliable:\n",
    "\n",
    "\\begin{align*}\n",
    "\\| \\nabla u - \\nabla u_h \\|_{L_2} & = \\| p - p_h \\|_{L_2} \\leq \n",
    "        \\| p_h - \\widetilde p_h \\|_{L_2} + \\| p - \\widetilde p_h \\|_{L_2} \\\\\n",
    "        & \\leq \\| p_h - \\widetilde p_h \\|_{L_2} + \\alpha \\| p - p_h \\|_{L_2},\n",
    "\\end{align*}\n",
    "and\n",
    "\n",
    "$$\n",
    "\\| \\nabla u - \\nabla u_h \\|_{L_2} \\leq \\frac{1}{1-\\alpha} \\| p_h - \\widetilde p_h \\|_{L_2}.\n",
    "$$\n",
    "It is also efficient, a similar short application of the triangle inequality.\n",
    "\n",
    "There is a rigorous analysis of the ZZ error estimator, e.g., by showing equivalence\n",
    "to the residual error estimator below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c214a0b-2c14-470f-9422-16531100c8ac",
   "metadata": {},
   "source": [
    "## Mesh refinement algorithms\n",
    "\n",
    "A posteriori error estimates are used to control recursive mesh refinement:\n",
    "\n",
    "> Start with initial mesh ${\\cal T}$ \\newline <br>\n",
    "> Loop <br>\n",
    "> $\\qquad$ compute fe solution $u_h$ on ${\\cal T}$ <br>\n",
    "> $\\qquad$ compute error estimator $\\eta_T (u_h, f)$ <br>\n",
    "> $\\qquad$ if $\\eta \\leq$ tolerance then stop <br>\n",
    "> $\\qquad$ refine elements with large $\\eta_T$ to obtain a new mesh\n",
    "\n",
    "The mesh refinement algorithm has to take care of\n",
    "\n",
    "* generating a sequence of regular meshes\n",
    "* generating a sequence of shape regular meshes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334baee0-7f3e-4656-aa1d-ba8377b7ec35",
   "metadata": {},
   "source": [
    "###  Red-Green Refinement\n",
    "A marked element is split into four equivalent elements (called red refinement):\n",
    "\n",
    "<img src=\"refine_irreg.png\" alt=\"Alternative text\" width=\"300\" align=\"center\"/>\n",
    "\n",
    "But, the obtained mesh is not regular. To avoid such irregular nodes,\n",
    "also neighboring elements must be split (called green closure):\n",
    "\n",
    "<img src=\"refine_reg.png\" alt=\"Alternative text\" width=\"300\" align=\"center\"/>\n",
    "\n",
    "If one continues to refine that way, the shape of the elements may get worse and worse:\n",
    "\n",
    "<img src=\"refinebad.png\" alt=\"Alternative text\" width=\"500\" align=\"center\"/>\n",
    "\n",
    "A solution is that elements of the green closure will not be further refined. \n",
    "Instead, remove the green closure, and replace it by red refinement. \n",
    "\n",
    "<img src=\"refinegood.png\" alt=\"Alternative text\" width=\"500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f902d56-eb1f-4028-80eb-eee9967005ac",
   "metadata": {},
   "source": [
    "### Marked edge bisection\n",
    "Each triangle has one marked edge. \n",
    "The triangle is only refined by cutting from the middle of the\n",
    "marked edge to the opposite vertex. The marked edges of the new triangles\n",
    "are the edges of the old triangle.\n",
    "\n",
    "If there occurs an irregular node, then also the neighbor triangle must be refined.\n",
    "\n",
    "<img src=\"bisect.png\" alt=\"Alternative text\" width=\"500\" align=\"center\"/>\n",
    "\n",
    "To ensure finite termination, one has to avoid cycles in the initial mesh. \n",
    "This can be obtained by first sorting the edges (e.g., by length), end then, \n",
    "always choose the largest edges as marked edge.\n",
    "\n",
    "Both of these refinement algorithms are also possible in 3D."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20accb2-a6b5-4ba9-b683-40de683ef5a9",
   "metadata": {},
   "source": [
    "## Flux-recovery error estimates with NGSolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f359ed-235c-4d21-b154-bca58a2c589b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ngsolve import *\n",
    "from netgen.occ import *\n",
    "from ngsolve.webgui import Draw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ae5558-652f-4cd7-adcd-66c5eec12968",
   "metadata": {},
   "source": [
    "We create a continuous, vector-valued `GridFunction` for the flux, and interpolate the finite element flux into it. Then we take element-wise the difference between the finite element flux, and the interpolated flux as element-wise error estimate. First we try for the Poisson equation, with constant $1$, where the flux equals the gradient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f29348-13fa-40a4-98be-e60463dbac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "lshape = Line(1).Rotate(90).Line(1).Rotate(90).Line(2) \\\n",
    "    .Rotate(90).Line(2).Rotate(90).Line(1).Close().Face()\n",
    "mesh = Mesh(OCCGeometry(lshape,dim=2).GenerateMesh(maxh=0.5))\n",
    "\n",
    "fes = H1(mesh,order=3, autoupdate=True, dirichlet=\".*\")\n",
    "u,v = fes.TnT()\n",
    "a = BilinearForm(grad(u)*grad(v)*dx)\n",
    "f = LinearForm(v*dx)\n",
    "gfu = GridFunction(fes, autoupdate=True)\n",
    "fesflux = VectorH1(mesh,order=3, autoupdate=True)\n",
    "gfflux = GridFunction(fesflux, autoupdate=True)\n",
    "lam = CF( 1 )\n",
    "hist = []\n",
    "\n",
    "def SolveEstimateMark():\n",
    "    a.Assemble()\n",
    "    f.Assemble()\n",
    "    gfu.vec.data = a.mat.Inverse(fes.FreeDofs())*f.vec\n",
    "\n",
    "    gfflux.Set(lam*grad(gfu))\n",
    "    errest = Integrate ( lam*(1/lam*gfflux-grad(gfu))**2, mesh, element_wise=True)\n",
    "    errmax = max(errest)\n",
    "    hist.append ( (fes.ndof, sqrt(sum(errest)) ) )\n",
    "    for i in range(mesh.GetNE(VOL)):\n",
    "        mesh.SetRefinementFlag(ElementId(VOL,i), errest[i] > 0.25*errmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1197c2c9-ed3e-4a51-be95-2cf3ff0ea8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SolveEstimateMark()\n",
    "while fes.ndof < 10000:\n",
    "    mesh.Refine()\n",
    "    SolveEstimateMark()\n",
    "\n",
    "Draw (mesh);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd96b94a-ed58-4753-a9b8-0e390e2dfc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.plot (*zip(*hist), '-*');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e703a8-80b9-47cc-9ee1-ca4a4e40438f",
   "metadata": {},
   "source": [
    "### Variable coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0811eae3-45ec-4383-8a2e-8893bc619a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeTwoMaterialMesh():\n",
    "    r = Rectangle(2,2).Face()\n",
    "    r.edges.name='dirichlet'\n",
    "    inner = MoveTo(0.5,0.5).Rectangle(1,1).Face()\n",
    "    outer = r-inner\n",
    "    outer.faces.name=\"outer\"\n",
    "    inner.faces.name=\"inner\"\n",
    "    shape =Glue([outer,inner])\n",
    "    return Mesh(OCCGeometry(shape,dim=2).GenerateMesh(maxh=0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad98451d-9993-40cc-8b1d-036126fa77fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = MakeTwoMaterialMesh()\n",
    "fes = H1(mesh, order=3, autoupdate=True, dirichlet=\"dirichlet\")\n",
    "u,v = fes.TnT()\n",
    "lam = mesh.MaterialCF( { \"inner\" : 5, \"outer\" : 1} )\n",
    "a = BilinearForm(lam*grad(u)*grad(v)*dx)\n",
    "f = LinearForm(v*dx(\"inner\"))\n",
    "gfu = GridFunction(fes, autoupdate=True)\n",
    "fesflux = VectorH1(mesh,order=3, autoupdate=True)\n",
    "gfflux = GridFunction(fesflux, autoupdate=True)\n",
    "\n",
    "hist = []\n",
    "SolveEstimateMark()\n",
    "while fes.ndof < 10000:\n",
    "    mesh.Refine()\n",
    "    SolveEstimateMark()\n",
    "\n",
    "Draw (mesh);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837a91db-4de3-406d-8bd2-eed2cccc3543",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.plot (*zip(*hist), '-*');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b25c26-17d4-49a9-aa5e-cb6b14bda367",
   "metadata": {},
   "source": [
    "We observe a very strong refinement along the material interface. This is unnecessary, since the solution is smooth on both sides, we only expect singularities at the corners. The problem is that the flux-averaging did an averaging of the full flux vector. The tangential component of it is not supposed to be continuous, and this it highly overestimates the error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a28506-6017-4a7f-a3ab-f72b067bc5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Draw (lam*grad(gfu)[0], mesh, order=2, min=-0.5, max=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8bf3df-04f9-4574-a895-e800b41b10b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Draw (gfflux[0], mesh, min=-0.5, max=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d43b453-dced-484a-ad5c-92089a76b3e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Draw (lam*grad(gfu)[0]-gfflux[0], mesh);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0318f728-e3d7-4fb7-9224-8049565cafa3",
   "metadata": {},
   "source": [
    "### Flux recovery in $H(\\operatorname{div})$\n",
    "\n",
    "The over-refinement along the edges can be overcome by averaging only the normal component of the flux, since only this is supposed to be continuous. This we obtain by recovering the flux in an $H(\\operatorname{div})$ finite element space: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389d42a1-c3c7-4428-8bcb-0d36d6455552",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = MakeTwoMaterialMesh()\n",
    "fes = H1(mesh,order=3, autoupdate=True, dirichlet=\"dirichlet\")\n",
    "u,v = fes.TnT()\n",
    "lam = mesh.MaterialCF( { \"inner\" : 5, \"outer\" : 1} )\n",
    "a = BilinearForm(lam*grad(u)*grad(v)*dx)\n",
    "f = LinearForm(v*dx(\"inner\"))\n",
    "gfu = GridFunction(fes, autoupdate=True)\n",
    "fesflux = HDiv(mesh,order=3, autoupdate=True)\n",
    "gfflux = GridFunction(fesflux, autoupdate=True)\n",
    "hist=[]\n",
    "\n",
    "SolveEstimateMark()\n",
    "while fes.ndof < 10000:\n",
    "    mesh.Refine()\n",
    "    SolveEstimateMark()\n",
    "\n",
    "Draw (mesh);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e7df24-e2bc-4e8b-91fa-d0a40a0d0166",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.plot (*zip(*hist), '-*');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180e3baf-d25e-4be1-bda6-4ab5caf289cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
